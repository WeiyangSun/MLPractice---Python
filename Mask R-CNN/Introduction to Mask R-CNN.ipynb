{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mask R-CNN is an extension of Faster R-CNN, which is widely used for object detection. For a given image, it returns the class labels and bounding box coordinates for each object in the image [refer to image shown below]. \n",
    "\n",
    "The Mask R-CNN framework is built on the Faster R-CNN. It returns, in addition to the outputs of Faster R-CNN (class labels and bounding box coordinates), an object mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Fast R-CNN.png'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How does Faster R-CNN work?\n",
    "\n",
    "Faster R-CNN uses a ConvNet to extract feature maps from images. These feature maps are passed through a Region Proposal Network (RPN) which returns candidate bounding boxes. Region of Interest (RoI) pooling layer applied on these candidate bounding boxes to bring all boxes to the same size. Finally, proposals are passed onto a fully-connected layer to classify and output bounding boxes for objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Fast R-CNN2.png'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How does Mask R-CNN work?\n",
    "\n",
    "Instead of using ConvNet, Mask R-CNN uses ResNet 101 architecture to extract feature maps from images. These feature maps are similarly passed into a Region Proposal Network (RPN) which predicts if an object is present in the candidate region or not. We will only focus on regions that contain some objects. The RoI converts all regions to the same shape. \n",
    "\n",
    "The difference between the 2 framework (Faster R-CNN and Mask R-CNN) is that, in addition, Mask R-CNN generates a segmentation mask. For all predicted regions, we compute the Intersection over Union (IoU - Area of Intersection / Area of Union). If IoU is greater than 0.5, then we will select the region, else ignore [refer to image shown below]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Fast R-CNN4.png'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Once we have narrowed down to RoI based on IoU, a mask branch is added to the existing architecture. This returns the segmentation mask for each region that contains an object. The first image below shows the full image being read in. The segmentation mask results in the blackout area observed in the second image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Fast R-CNN5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Fast R-CNN6.png'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mask R-CNN then simply predicts the masks for all the objects in the images. The image below shows the 4 different architecture, from R-CNN (start model) to Mask-RCNN (final model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Fast R-CNN3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
